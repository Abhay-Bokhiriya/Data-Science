{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Categorically Speaking\n",
    "\n",
    "**Notice: This notebook is a modification of [cats.ipynb and targetencode.ipynb](https://mlbook.explained.ai/notebooks/index.html) by Terence Parr and Jeremy Howard, which were used by permission of the author.**\n",
    "\n",
    "Please use this notebook to follow along with the lectures this week. \n",
    "\n",
    "There may be minor differences between the notebook seen in the lecture videos and this one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HsaH_N8N7vG"
   },
   "source": [
    "## Recap\n",
    "\n",
    "Recall that to train a model we need:\n",
    "\n",
    " - all the data to be numeric;\n",
    " - no missing data/values.\n",
    " \n",
    "And what we have done so far is:\n",
    " - ignored non-numeric data;\n",
    " - built and evaluated a random forest model, which had:\n",
    "     - a poor avg $R^2$ and *mean absolute error* on the validation data;\n",
    "     - high variance in $R^2$ and *mean absolute error* on the validation data;\n",
    " - explored our data for anomalies in the context of our objective to predict apartment rental prices for a typical apartment in New York City;\n",
    " - cleaned our data to remove the anomalies we discovered;\n",
    " - built and evaluated a random forest model using the cleaned data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reestablish Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "6P6fbYCnN7vH"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "dJ83sz4UN7vR",
    "outputId": "f604b55c-b267-42a2-b595-b460360679e0"
   },
   "outputs": [],
   "source": [
    "rent = pd.read_csv('rent.csv')\n",
    "\n",
    "rent_clean = rent[(rent['price'] > 1000) & (rent['price'] < 10000)]\n",
    "rent_clean = rent_clean[(rent_clean['longitude'] !=0) | (rent_clean['latitude']!=0)]\n",
    "rent_clean = rent_clean[(rent_clean['latitude']>40.55) &\n",
    "                        (rent_clean['latitude']<40.94) &\n",
    "                        (rent_clean['longitude']>-74.1) &\n",
    "                        (rent_clean['longitude']<-73.67)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out-of-bag R^2 for baseline model is: 0.8680714155784182\n"
     ]
    }
   ],
   "source": [
    "numfeatures = ['bathrooms', 'bedrooms', 'longitude', 'latitude']\n",
    "\n",
    "X = rent_clean[numfeatures]\n",
    "y = rent_clean['price']\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, n_jobs=-1, oob_score=True)\n",
    "rf.fit(X, y)\n",
    "\n",
    "oob_baseline = rf.oob_score_\n",
    "print(f\"Out-of-bag R^2 for baseline model is: {oob_baseline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $R^2$ Reminder\n",
    "\n",
    "Recall the formula:\n",
    "\n",
    "$$\n",
    "R^2 = 1 - \\frac{\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n}(y_i - \\bar{y})^2}\n",
    "$$\n",
    "\n",
    "This tells us that:\n",
    "- $R^2 = 1$ means our model is perfect; \n",
    "- $R^2 \\approx 0$ means our model does no better than just predicting the average;\n",
    "- $R^2 \\lt\\lt 0$ means our model does worse than predicting the average.\n",
    "\n",
    "Also, as $R^2 \\rightarrow 1$ it gets harder and harder to improve model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Indicators\n",
    "\n",
    "We are not only interested in $R^2$. We would also like to know: \n",
    "- how much work the random forest model has to do to capture the relationship between the features and the target; \n",
    "- the typical tree depth, as this will impact the speed of predictions for new data;\n",
    "- how important different features are for a given model.\n",
    "\n",
    "To help with this we will need to install a new package: `rfpimp`. (Note: you will see some *FutureWarning* messages when using this package but these can be ignored as they are just warnings that some parts of the *sklearn* code are changing in the future.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rfpimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MCASSAR\\Anaconda3\\envs\\DAB300-F20\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from rfpimp import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we will be evaluating many models this way, we will use some functions to help keep our code clean:\n",
    "- one to evaluate our model and report the OOB score, the number of nodes across all trees in the forest, and the median tree depth in the forest; and, \n",
    "- one to show the feature importances for a given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X, y):\n",
    "    rf = RandomForestRegressor(n_estimators=100, n_jobs=-1, oob_score=True)\n",
    "    rf.fit(X, y)\n",
    "    oob = rf.oob_score_\n",
    "    n = rfnnodes(rf)\n",
    "    h = np.median(rfmaxdepths(rf))\n",
    "    print(f\"OOB R^2 is {oob:.5f} using {n:,d} tree nodes with {h} median tree depth\")\n",
    "    return rf, oob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showimp(rf, X, y):\n",
    "    features = list(X.columns)\n",
    "    features.remove('latitude')\n",
    "    features.remove('longitude')\n",
    "    features += [['latitude','longitude']]\n",
    "\n",
    "    I = importances(rf, X, y, features=features)\n",
    "    plot_importances(I, color='#4575b4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try both of these out on our baseline model that uses only the cleaned numeric data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOB R^2 is 0.86833 using 2,434,190 tree nodes with 35.0 median tree depth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(RandomForestRegressor(n_jobs=-1, oob_score=True), 0.8683290305018332)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x108 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "showimp(rf, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "Many times, a model's ability to generalize (predict) well is not all we are hoping for; we would also like to understand what the model is doing, which is referred to as a model's interpretability. Random Forests have this as a built in feature, however the implementation in *sklearn* suffers from bias when:\n",
    "- the scales of the features vary; and/or, \n",
    "- there are many categories for a feature.\n",
    "\n",
    "A better way to assess feature importance, in any model, is to use:\n",
    "- permutation importance; or \n",
    "- dropped feature importance.\n",
    "\n",
    "##### Permutation Importance\n",
    "\n",
    "We can calculate the feature importances using a permutation method, which consists of the following steps:\n",
    "- use all features and establish a baseline value for $R^2$;\n",
    "- select one feature and randomly permute its values leaving all other features unchanged;\n",
    "- calculate the new value for $R^2$ with this one feature permuted;\n",
    "- calculate the change in $R^2$ from the baseline; and, \n",
    "- repeat for the other features.\n",
    "\n",
    "Let's see how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perm_importances(X, y):\n",
    "    rf = RandomForestRegressor(n_estimators=100, n_jobs=-1, oob_score=True, random_state=999)\n",
    "    rf.fit(X, y)\n",
    "    r2 = rf.oob_score_\n",
    "    print(f\"Baseline R^2 with no columns permuted: {r2:.5f}\\n\")\n",
    "    for col in X.columns:\n",
    "        X_col = X.copy()\n",
    "        X_col[col] = X_col[col].sample(frac=1).values\n",
    "        rf.fit(X_col, y)\n",
    "        r2_col = rf.oob_score_\n",
    "        print(f\"Permuting column {col}: new R^2 is {r2_col:.5f} and difference from baseline is {r2 - r2_col:.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline R^2 with no columns permuted: 0.86763\n",
      "\n",
      "Permuting column bathrooms: new R^2 is 0.81311 and difference from baseline is 0.05452\n",
      "Permuting column bedrooms: new R^2 is 0.75357 and difference from baseline is 0.11406\n",
      "Permuting column longitude: new R^2 is 0.68464 and difference from baseline is 0.18298\n",
      "Permuting column latitude: new R^2 is 0.68668 and difference from baseline is 0.18095\n"
     ]
    }
   ],
   "source": [
    "perm_importances(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dropped Column Importance\n",
    "\n",
    "We can also calculate the importance of the features using a dropped column, which consists of the following steps:\n",
    "- use all features and establish a baseline value for $R^2$;\n",
    "- select one feature and remove it from the data;\n",
    "- calculate the new value for $R^2$ with this one feature removed;\n",
    "- calculate the change in $R^2$ from the baseline; and, \n",
    "- repeat for the other features.\n",
    "\n",
    "Let's see how this works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_importances(X, y):\n",
    "    rf = RandomForestRegressor(n_estimators=100, n_jobs=-1, oob_score=True, random_state=999)\n",
    "    rf.fit(X, y)\n",
    "    r2 = rf.oob_score_\n",
    "    print(f\"Baseline R^2 with no columns dropped: {r2:.5f}\\n\")\n",
    "    for col in X.columns:\n",
    "        X_col = X.copy()\n",
    "        X_col = X_col.drop(col, axis=1) \n",
    "        rf.fit(X_col, y)\n",
    "        r2_col = rf.oob_score_\n",
    "        print(f\"Dropping column {col}: new R^2 is {r2_col:.5f} and difference from baseline is {r2 - r2_col:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline R^2 with no columns dropped: 0.86763\n",
      "\n",
      "Dropping column bathrooms: new R^2 is 0.81941 and difference from baseline is 0.04821\n",
      "Dropping column bedrooms: new R^2 is 0.77719 and difference from baseline is 0.09044\n",
      "Dropping column longitude: new R^2 is 0.73451 and difference from baseline is 0.13311\n",
      "Dropping column latitude: new R^2 is 0.74144 and difference from baseline is 0.12619\n"
     ]
    }
   ],
   "source": [
    "drop_importances(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Be Careful With Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>bedrooms_dup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.9539</td>\n",
       "      <td>40.7108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.9722</td>\n",
       "      <td>40.7513</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.9625</td>\n",
       "      <td>40.7575</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>-73.9425</td>\n",
       "      <td>40.7145</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.9743</td>\n",
       "      <td>40.7439</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bathrooms  bedrooms  longitude  latitude  bedrooms_dup\n",
       "0        1.0         1   -73.9539   40.7108             1\n",
       "1        1.0         2   -73.9722   40.7513             2\n",
       "2        1.0         2   -73.9625   40.7575             2\n",
       "3        1.5         3   -73.9425   40.7145             3\n",
       "4        1.0         0   -73.9743   40.7439             0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dup = X.copy()\n",
    "X_dup['bedrooms_dup'] = X_dup['bedrooms']\n",
    "X_dup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline R^2 with no columns dropped: 0.86736\n",
      "\n",
      "Dropping column bathrooms: new R^2 is 0.81960 and difference from baseline is 0.04776\n",
      "Dropping column bedrooms: new R^2 is 0.86764 and difference from baseline is -0.00027\n",
      "Dropping column longitude: new R^2 is 0.73442 and difference from baseline is 0.13294\n",
      "Dropping column latitude: new R^2 is 0.74139 and difference from baseline is 0.12597\n",
      "Dropping column bedrooms_dup: new R^2 is 0.86763 and difference from baseline is -0.00026\n"
     ]
    }
   ],
   "source": [
    "drop_importances(X_dup, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Breaking Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>bedrooms_dup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-73.9539</td>\n",
       "      <td>40.7108</td>\n",
       "      <td>0.808281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.9722</td>\n",
       "      <td>40.7513</td>\n",
       "      <td>-0.015214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-73.9625</td>\n",
       "      <td>40.7575</td>\n",
       "      <td>2.911445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>-73.9425</td>\n",
       "      <td>40.7145</td>\n",
       "      <td>9.562779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-73.9743</td>\n",
       "      <td>40.7439</td>\n",
       "      <td>1.702281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   bathrooms  bedrooms  longitude  latitude  bedrooms_dup\n",
       "0        1.0         1   -73.9539   40.7108      0.808281\n",
       "1        1.0         2   -73.9722   40.7513     -0.015214\n",
       "2        1.0         2   -73.9625   40.7575      2.911445\n",
       "3        1.5         3   -73.9425   40.7145      9.562779\n",
       "4        1.0         0   -73.9743   40.7439      1.702281"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise = np.random.normal(0, 2, X_dup.shape[0])\n",
    "\n",
    "X_dup['bedrooms_dup'] = X_dup['bedrooms'] + noise\n",
    "X_dup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline R^2 with no columns dropped: 0.84715\n",
      "\n",
      "Dropping column bathrooms: new R^2 is 0.78743 and difference from baseline is 0.05972\n",
      "Dropping column bedrooms: new R^2 is 0.72391 and difference from baseline is 0.12324\n",
      "Dropping column longitude: new R^2 is 0.67930 and difference from baseline is 0.16785\n",
      "Dropping column latitude: new R^2 is 0.68463 and difference from baseline is 0.16252\n",
      "Dropping column bedrooms_dup: new R^2 is 0.86763 and difference from baseline is -0.02048\n"
     ]
    }
   ],
   "source": [
    "drop_importances(X_dup, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "new_initial_model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
